import numpy as np
import scipy.io
import matplotlib.pyplot as plt
import seaborn as sns
import time
from scipy.io import loadmat
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, confusion_matrix
from sklearn.metrics import pairwise_distances
import matplotlib.pyplot as plt
import seaborn as sns
import os

# --- Load Salinas-A data ---
def load_salinas_A():
    data = scipy.io.loadmat('ML/SalinasA_corrected.mat')['salinasA_corrected']
    #print(data)
    #print("Shape of Salinas-A data:", data.shape)
    labels = scipy.io.loadmat('ML/SalinasA_gt.mat')['salinasA_gt']
    #print(labels)
    #print("Shape of Salinas-A labels:", labels.shape)
    
    # Separate training and testing data, each 3rd row for training, the others for testing
    training_data = data[::3, :, :]
    training_labels = labels[::3, :]
    mask = np.ones(data.shape[0], dtype=bool)
    mask[::3] = False
    testing_data = data[mask, :, :]
    testing_labels = labels[mask, :]
    #print("Training data shape:", training_data.shape)
    #print("Testing data shape:", testing_data.shape)
    #print("Training labels shape:", training_labels.shape)
    #print("Testing labels shape:", testing_labels.shape)
    return training_data, training_labels, testing_data, testing_labels

# S√©lection al√©atoire de K points de r√©f√©rence par classe
def select_reference_points(training_data, training_labels):
    classes = np.unique(training_labels[training_labels > 0])
    #print(classes)
    #print(type(classes))
    R = [] # Reference points, 3 per classes selected randomly
    T = [] # Labels of reference points

    for label in classes:
        class_indices = np.where(training_labels == label)[0] # Indices of the current class
        if len(class_indices) < 3:
            raise ValueError(f"Not enough points for the class {label}.")
        chosen_indices = np.random.choice(class_indices, size=3, replace=False)
        R.extend(training_data[chosen_indices])
        T.extend([label] * 3)
    #print("Reference points selected:", len(R))
    #print(R)
    #print(type(T[0]))
    return np.array(R), np.array(T)


# Construction des matrices de distance
def build_distance_matrices(X, ref_indices, Y, T_labels):
    X_ref = X[ref_indices]
    Dx = pairwise_distances(X, X_ref, metric='euclidean')
    Dy = np.array([[0 if y == tk else 1 for tk in T_labels] for y in Y])
    return Dx, Dy

# Initialisation du mod√®le RLS
def initialize_rls(Dx, Dy):
    P = np.linalg.inv(Dx.T @ Dx + 1e-6 * np.eye(Dx.shape[1]))  # stabilit√© num√©rique
    B = P @ Dx.T @ Dy
    return P, B

# Mise √† jour RLS
def rls_update(Dx_i, Dy_i, P, B):
    Px = P @ Dx_i.T
    S = np.eye(Dx_i.shape[0]) + Dx_i @ Px
    P_new = P - Px @ np.linalg.inv(S) @ Dx_i @ P
    K = P_new @ Dx_i.T
    B_new = B + K @ (Dy_i - Dx_i @ B)
    return P_new, B_new

# Pr√©diction
def predict_label(x, X_ref, B, T_labels):
    dx = pairwise_distances([x], X_ref, metric='euclidean')
    dy = dx @ B
    return T_labels[np.argmin(dy)]

# Fonction principale
def main_rls_pipeline(path_X, path_Y, K_ref=5, test_size=0.2, n_updates=20):
    X, Y = load_salinas(path_X, path_Y)
    mask = Y > 0
    X, Y = X[mask], Y[mask]

    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size, stratify=Y, random_state=42)

    # Chargement mod√®le s'il existe
    if all(os.path.exists(f) for f in ["model_B.npy", "model_P.npy", "model_ref_points.npy", "model_T_labels.npy"]):
        print("üîÅ Chargement du mod√®le existant...")
        B = np.load("model_B.npy")
        P = np.load("model_P.npy")
        X_ref = np.load("model_ref_points.npy")
        T_labels = np.load("model_T_labels.npy")
    else:
        print("üÜï Initialisation d'un nouveau mod√®le...")
        ref_indices = select_reference_points(X_train, Y_train, K=K_ref)
        X_ref = X_train[ref_indices]
        T_labels = Y_train[ref_indices]
        Dx0, Dy0 = build_distance_matrices(X_train, ref_indices, Y_train, T_labels)
        P, B = initialize_rls(Dx0, Dy0)

    # Mises √† jour r√©cursives
    for _ in range(n_updates):
        idx = np.random.randint(0, len(X_train))
        x_new = X_train[idx:idx+1]
        y_new = Y_train[idx:idx+1]
        Dx_i = pairwise_distances(x_new, X_ref, metric='euclidean')
        Dy_i = np.array([[0 if y_new[0] == tk else 1 for tk in T_labels]])
        P, B = rls_update(Dx_i, Dy_i, P, B)

    # Pr√©dictions
    predictions = [predict_label(x, X_ref, B, T_labels) for x in X_test]
    acc = accuracy_score(Y_test, predictions)
    cm = confusion_matrix(Y_test, predictions, labels=np.unique(Y_test))
    
    print(f"\n‚úÖ Accuracy globale : {acc:.4f}")

    # Affichage de la matrice de confusion
    plt.figure(figsize=(10, 8))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                xticklabels=np.unique(Y_test), yticklabels=np.unique(Y_test))
    plt.xlabel("Pr√©dictions")
    plt.ylabel("V√©ritables")
    plt.title("Matrice de confusion - RLS")
    plt.tight_layout()
    plt.show()

    # Sauvegarde du mod√®le
    print("üíæ Sauvegarde du mod√®le...")
    np.save("model_B.npy", B)
    np.save("model_P.npy", P)
    np.save("model_ref_points.npy", X_ref)
    np.save("model_T_labels.npy", T_labels)
    print("‚úÖ Mod√®le sauvegard√©.")

# Lancer le programme
if __name__ == "__main__":
    #main_rls_pipeline("ML/SalinasA_corrected.mat", "ML/SalinasA_gt.mat")
    training_data, training_labels, testing_data, testing_labels = load_salinas_A()
    select_reference_points(training_data, training_labels)
